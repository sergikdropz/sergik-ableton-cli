"""
sync_cloud.py ‚Äî Sergik AI Ecosystem Mode
Version: 1.0
Author: Sergik AI
Purpose:
    Sync the Sergik AI dataset with cloud storage and/or GitHub,
    while maintaining version metadata, checksums, and logs.

Features:
    - Dataset versioning with SHA-256 checksums
    - Git commit & push automation
    - AWS S3 upload with progress tracking
    - Version manifest generation (dataset_versions.json)
    - Incremental sync (only upload changed files)
    - Dataset integrity verification

Supports:
    - Local Git commit & push
    - AWS S3 upload with checksum validation
    - Firebase Storage (via sergik_ml.connectors.cloud_storage)
    - Version manifest generation

Usage:
    python scripts/sync_cloud.py                    # Version only
    python scripts/sync_cloud.py --push             # Version + Git push
    python scripts/sync_cloud.py --s3               # Version + S3 upload
    python scripts/sync_cloud.py --push --s3        # Full sync
    python scripts/sync_cloud.py --verify           # Verify checksums
"""

import argparse
import hashlib
import json
import logging
import os
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
from dataclasses import dataclass, field, asdict

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# Add parent to path for imports
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))


# ============================================================================
# Configuration
# ============================================================================

@dataclass
class SyncConfig:
    """Sync configuration."""
    # Directories to sync
    dataset_dirs: List[str] = field(default_factory=lambda: [
        "data/catalog",
        "data/manifests",
        "data/analysis",
        "knowledge",
    ])
    
    # Patterns to exclude
    exclude_patterns: List[str] = field(default_factory=lambda: [
        "*.pyc",
        "__pycache__",
        ".DS_Store",
        "*.tmp",
        "*.log",
        ".git",
        "*.bak",
    ])
    
    # Version manifest path
    version_file: str = "data/dataset_versions.json"
    
    # Cloud settings
    s3_bucket: str = os.getenv("SERGIK_S3_BUCKET", "sergik-datasets")
    s3_prefix: str = "sergik_ai/"
    
    # Git settings
    git_commit_message: str = "Auto-sync: Sergik AI dataset update"
    git_remote: str = "origin"
    git_branch: str = "main"


# ============================================================================
# Data Classes
# ============================================================================

@dataclass
class FileInfo:
    """Information about a single file."""
    path: str
    relative_path: str
    checksum: str
    size_bytes: int
    modified: str
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass
class VersionEntry:
    """Single version entry in manifest."""
    version: int
    timestamp: str
    file_count: int
    total_size_bytes: int
    checksum_algorithm: str = "sha256"
    files: List[Dict[str, Any]] = field(default_factory=list)
    changed_files: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


# ============================================================================
# Utilities
# ============================================================================

def sha256sum(filepath: str) -> str:
    """Calculate SHA-256 checksum for a file."""
    h = hashlib.sha256()
    with open(filepath, "rb") as f:
        for chunk in iter(lambda: f.read(8192), b""):
            h.update(chunk)
    return h.hexdigest()


def should_exclude(path: Path, exclude_patterns: List[str]) -> bool:
    """Check if path should be excluded."""
    path_str = str(path)
    name = path.name
    
    for pattern in exclude_patterns:
        if pattern.startswith("*"):
            # Extension match
            if name.endswith(pattern[1:]):
                return True
        elif pattern in path_str:
            return True
        elif name == pattern:
            return True
    
    return False


def format_size(size_bytes: int) -> str:
    """Format bytes to human readable string."""
    for unit in ["B", "KB", "MB", "GB"]:
        if size_bytes < 1024:
            return f"{size_bytes:.2f} {unit}"
        size_bytes /= 1024
    return f"{size_bytes:.2f} TB"


# ============================================================================
# Dataset Scanner
# ============================================================================

class DatasetScanner:
    """Scans dataset directories and generates file manifests."""
    
    def __init__(self, config: SyncConfig):
        """Initialize scanner."""
        self.config = config
        self.project_root = PROJECT_ROOT
    
    def scan(self) -> List[FileInfo]:
        """Scan all dataset directories."""
        all_files = []
        
        for dir_path in self.config.dataset_dirs:
            full_path = self.project_root / dir_path
            if full_path.exists():
                files = self._scan_directory(full_path, dir_path)
                all_files.extend(files)
            else:
                logger.warning(f"Directory not found: {full_path}")
        
        return all_files
    
    def _scan_directory(self, directory: Path, base_path: str) -> List[FileInfo]:
        """Scan a single directory recursively."""
        files = []
        
        for item in directory.rglob("*"):
            if item.is_file():
                if should_exclude(item, self.config.exclude_patterns):
                    continue
                
                try:
                    relative = str(item.relative_to(self.project_root))
                    checksum = sha256sum(str(item))
                    stat = item.stat()
                    
                    files.append(FileInfo(
                        path=str(item),
                        relative_path=relative,
                        checksum=checksum,
                        size_bytes=stat.st_size,
                        modified=datetime.fromtimestamp(stat.st_mtime).isoformat(),
                    ))
                except Exception as e:
                    logger.error(f"Error scanning {item}: {e}")
        
        return files


# ============================================================================
# Version Manager
# ============================================================================

class VersionManager:
    """Manages dataset versioning and manifests."""
    
    def __init__(self, config: SyncConfig):
        """Initialize version manager."""
        self.config = config
        self.project_root = PROJECT_ROOT
        self.version_path = self.project_root / config.version_file
    
    def load_manifest(self) -> List[VersionEntry]:
        """Load existing version manifest."""
        if not self.version_path.exists():
            return []
        
        try:
            with open(self.version_path, "r") as f:
                data = json.load(f)
            
            return [
                VersionEntry(
                    version=v["version"],
                    timestamp=v["timestamp"],
                    file_count=v["file_count"],
                    total_size_bytes=v.get("total_size_bytes", 0),
                    files=v.get("files", []),
                    changed_files=v.get("changed_files", []),
                )
                for v in data
            ]
        except Exception as e:
            logger.error(f"Error loading manifest: {e}")
            return []
    
    def save_manifest(self, versions: List[VersionEntry]):
        """Save version manifest."""
        self.version_path.parent.mkdir(parents=True, exist_ok=True)
        
        data = [v.to_dict() for v in versions]
        
        with open(self.version_path, "w") as f:
            json.dump(data, f, indent=2)
        
        logger.info(f"‚úÖ Saved version manifest: {self.version_path}")
    
    def create_version(
        self,
        files: List[FileInfo],
        previous_versions: List[VersionEntry]
    ) -> VersionEntry:
        """Create new version entry."""
        # Determine version number
        version_num = len(previous_versions) + 1
        
        # Find changed files
        changed = []
        if previous_versions:
            prev_files = {f["relative_path"]: f["checksum"] for f in previous_versions[-1].files}
            for file in files:
                if file.relative_path not in prev_files:
                    changed.append(file.relative_path)
                elif prev_files[file.relative_path] != file.checksum:
                    changed.append(file.relative_path)
        else:
            changed = [f.relative_path for f in files]
        
        # Calculate total size
        total_size = sum(f.size_bytes for f in files)
        
        return VersionEntry(
            version=version_num,
            timestamp=datetime.utcnow().isoformat(),
            file_count=len(files),
            total_size_bytes=total_size,
            files=[f.to_dict() for f in files],
            changed_files=changed,
        )
    
    def verify_integrity(self) -> Tuple[bool, List[str]]:
        """Verify dataset integrity against manifest."""
        versions = self.load_manifest()
        
        if not versions:
            return True, ["No version manifest found"]
        
        latest = versions[-1]
        issues = []
        
        for file_info in latest.files:
            path = self.project_root / file_info["relative_path"]
            
            if not path.exists():
                issues.append(f"Missing: {file_info['relative_path']}")
                continue
            
            current_checksum = sha256sum(str(path))
            if current_checksum != file_info["checksum"]:
                issues.append(f"Modified: {file_info['relative_path']}")
        
        return len(issues) == 0, issues


# ============================================================================
# Git Operations
# ============================================================================

class GitManager:
    """Manages Git operations."""
    
    def __init__(self, config: SyncConfig):
        """Initialize Git manager."""
        self.config = config
        self.project_root = PROJECT_ROOT
    
    def is_git_repo(self) -> bool:
        """Check if project is a Git repository."""
        return (self.project_root / ".git").exists()
    
    def has_changes(self) -> bool:
        """Check if there are uncommitted changes."""
        try:
            result = subprocess.run(
                ["git", "status", "--porcelain"],
                cwd=self.project_root,
                capture_output=True,
                text=True
            )
            return bool(result.stdout.strip())
        except Exception:
            return False
    
    def commit_and_push(self, message: Optional[str] = None) -> bool:
        """Commit and push changes."""
        if not self.is_git_repo():
            logger.error("Not a Git repository")
            return False
        
        message = message or self.config.git_commit_message
        
        try:
            # Stage all changes
            subprocess.run(
                ["git", "add", "-A"],
                cwd=self.project_root,
                check=True
            )
            
            # Commit
            subprocess.run(
                ["git", "commit", "-m", message],
                cwd=self.project_root,
                check=True
            )
            
            # Push
            subprocess.run(
                ["git", "push", self.config.git_remote, self.config.git_branch],
                cwd=self.project_root,
                check=True
            )
            
            logger.info("‚úÖ Git push complete")
            return True
            
        except subprocess.CalledProcessError as e:
            logger.error(f"Git operation failed: {e}")
            return False


# ============================================================================
# S3 Sync
# ============================================================================

class S3Sync:
    """Syncs dataset to AWS S3."""
    
    def __init__(self, config: SyncConfig):
        """Initialize S3 sync."""
        self.config = config
        self.project_root = PROJECT_ROOT
        self._client = None
    
    def _get_client(self):
        """Get or create S3 client."""
        if self._client is None:
            try:
                import boto3
                self._client = boto3.client("s3")
            except ImportError:
                logger.error("boto3 not installed. Install: pip install boto3")
                raise
        return self._client
    
    def sync(self, files: List[FileInfo], changed_only: bool = True) -> int:
        """Sync files to S3."""
        try:
            client = self._get_client()
        except ImportError:
            return 0
        
        uploaded = 0
        
        for file in files:
            remote_path = f"{self.config.s3_prefix}{file.relative_path}"
            
            # Check if file needs upload
            if changed_only:
                if not self._needs_upload(client, remote_path, file.checksum):
                    continue
            
            try:
                client.upload_file(
                    file.path,
                    self.config.s3_bucket,
                    remote_path,
                    ExtraArgs={
                        "Metadata": {
                            "checksum": file.checksum,
                            "source": "sergik_ml",
                        }
                    }
                )
                logger.info(f"‚òÅÔ∏è Uploaded: {file.relative_path}")
                uploaded += 1
                
            except Exception as e:
                logger.error(f"S3 upload failed for {file.relative_path}: {e}")
        
        return uploaded
    
    def _needs_upload(self, client, remote_path: str, checksum: str) -> bool:
        """Check if file needs to be uploaded."""
        try:
            response = client.head_object(
                Bucket=self.config.s3_bucket,
                Key=remote_path
            )
            remote_checksum = response.get("Metadata", {}).get("checksum", "")
            return remote_checksum != checksum
        except:
            return True


# ============================================================================
# Main Sync Orchestrator
# ============================================================================

class DatasetSync:
    """Main sync orchestrator."""
    
    def __init__(self, config: Optional[SyncConfig] = None):
        """Initialize sync."""
        self.config = config or SyncConfig()
        self.scanner = DatasetScanner(self.config)
        self.version_mgr = VersionManager(self.config)
        self.git_mgr = GitManager(self.config)
        self.s3_sync = S3Sync(self.config)
    
    def run(
        self,
        push_git: bool = False,
        sync_s3: bool = False,
        verify_only: bool = False,
    ) -> Dict[str, Any]:
        """Run sync operation."""
        results = {
            "version": None,
            "files_scanned": 0,
            "files_changed": 0,
            "total_size": 0,
            "git_pushed": False,
            "s3_uploaded": 0,
            "errors": [],
        }
        
        # Verify only mode
        if verify_only:
            valid, issues = self.version_mgr.verify_integrity()
            results["integrity_valid"] = valid
            results["integrity_issues"] = issues
            return results
        
        # Scan dataset
        logger.info("üìÇ Scanning dataset directories...")
        files = self.scanner.scan()
        results["files_scanned"] = len(files)
        results["total_size"] = sum(f.size_bytes for f in files)
        
        logger.info(f"   Found {len(files)} files ({format_size(results['total_size'])})")
        
        # Load existing versions and create new
        logger.info("üìã Updating version manifest...")
        versions = self.version_mgr.load_manifest()
        new_version = self.version_mgr.create_version(files, versions)
        
        results["version"] = new_version.version
        results["files_changed"] = len(new_version.changed_files)
        
        if new_version.changed_files:
            logger.info(f"   {len(new_version.changed_files)} files changed since last version")
            for f in new_version.changed_files[:5]:
                logger.info(f"      - {f}")
            if len(new_version.changed_files) > 5:
                logger.info(f"      ... and {len(new_version.changed_files) - 5} more")
        else:
            logger.info("   No changes detected")
        
        # Save new version
        versions.append(new_version)
        self.version_mgr.save_manifest(versions)
        
        # Git push
        if push_git:
            logger.info("üì§ Pushing to Git...")
            if self.git_mgr.is_git_repo():
                results["git_pushed"] = self.git_mgr.commit_and_push(
                    f"Dataset sync v{new_version.version}: {len(new_version.changed_files)} files changed"
                )
            else:
                logger.warning("Not a Git repository - skipping push")
        
        # S3 sync
        if sync_s3:
            logger.info("‚òÅÔ∏è Syncing to S3...")
            try:
                results["s3_uploaded"] = self.s3_sync.sync(files, changed_only=True)
                logger.info(f"   Uploaded {results['s3_uploaded']} files to S3")
            except Exception as e:
                logger.error(f"S3 sync failed: {e}")
                results["errors"].append(str(e))
        
        return results


# ============================================================================
# CLI Entry Point
# ============================================================================

def main():
    """Run sync from command line."""
    parser = argparse.ArgumentParser(
        description="Sergik AI Dataset Sync & Versioning",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    # Create new version (local only)
    python scripts/sync_cloud.py
    
    # Version and push to Git
    python scripts/sync_cloud.py --push
    
    # Version and upload to S3
    python scripts/sync_cloud.py --s3
    
    # Full sync (Git + S3)
    python scripts/sync_cloud.py --push --s3
    
    # Verify dataset integrity
    python scripts/sync_cloud.py --verify

Environment Variables:
    SERGIK_S3_BUCKET    S3 bucket name (default: sergik-datasets)
    AWS_ACCESS_KEY_ID   AWS credentials (for S3 sync)
    AWS_SECRET_ACCESS_KEY
        """
    )
    
    parser.add_argument(
        "--push", "-p",
        action="store_true",
        help="Commit and push to Git"
    )
    parser.add_argument(
        "--s3", "-s",
        action="store_true",
        help="Upload to S3"
    )
    parser.add_argument(
        "--verify", "-v",
        action="store_true",
        help="Verify dataset integrity only"
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Enable verbose logging"
    )
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    print("=" * 60)
    print("üåê SERGIK AI ‚Äî Dataset Sync & Versioning")
    print("=" * 60)
    
    # Run sync
    sync = DatasetSync()
    results = sync.run(
        push_git=args.push,
        sync_s3=args.s3,
        verify_only=args.verify,
    )
    
    # Print results
    print("\n" + "=" * 60)
    print("üìä SYNC RESULTS")
    print("=" * 60)
    
    if args.verify:
        valid = results.get("integrity_valid", False)
        issues = results.get("integrity_issues", [])
        
        if valid:
            print("   ‚úÖ Dataset integrity verified")
        else:
            print("   ‚ùå Integrity issues found:")
            for issue in issues[:10]:
                print(f"      - {issue}")
            if len(issues) > 10:
                print(f"      ... and {len(issues) - 10} more")
    else:
        print(f"   Version: {results.get('version', 'N/A')}")
        print(f"   Files scanned: {results.get('files_scanned', 0)}")
        print(f"   Files changed: {results.get('files_changed', 0)}")
        print(f"   Total size: {format_size(results.get('total_size', 0))}")
        
        if args.push:
            status = "‚úÖ" if results.get("git_pushed") else "‚ùå"
            print(f"   Git push: {status}")
        
        if args.s3:
            print(f"   S3 uploads: {results.get('s3_uploaded', 0)}")
        
        if results.get("errors"):
            print("\n   ‚ö†Ô∏è Errors:")
            for err in results["errors"]:
                print(f"      - {err}")
    
    print("=" * 60)
    print("‚úÖ Sync complete")


if __name__ == "__main__":
    main()

